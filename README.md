# âœˆï¸ Aircraft Stall Handler and Analysis using Reinforcement Learning and Historical Datasets

An intelligent flight simulation tool that uses reinforcement learning to detect and recover from aircraft stall conditions, visualized through a modern PyQt6 GUI. The system is capable of both training and evaluating agents in a custom Gym environment using simplified flight dynamics.

---

## ğŸ“Œ Overview

This project features:

- A **custom reinforcement learning environment** simulating aircraft stall behavior.
- A **PPO agent** (from Stable-Baselines3) trained to recover from stall.
- A **PyQt6 GUI** for live simulation, analysis, and control.
- **Real-time plots** and **flight metrics tables** for post-simulation review.

The goal is to simulate stall recovery with interpretable metrics and a user-friendly interface suitable for researchers, engineers, or enthusiasts.

---

## ğŸ§  Key Components

- `AircraftSHAgent.py` â€“ Contains the custom Gym environment and training/evaluation logic.
- `main.py` â€“ GUI application for simulation, visualization, training, and analysis.

---

## ğŸš€ Features

- âœ… Train and evaluate a stall recovery RL agent.
- âœ… Real-time simulation with graphical plots.
- âœ… Flight metrics table with color-coded statuses.
- âœ… Stall detection alerts with automatic adjustment.
- âœ… Scrollable analysis tab with multiple time-series plots.

---

## ğŸ› ï¸ Installation

### Requirements
- Python 3.10+
- PyQt6
- Gymnasium
- Stable-Baselines3
- NumPy
- Matplotlib

### Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/aircraft-stall-handler.git
cd aircraft-stall-handler

# Create a virtual environment (optional)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
â–¶ï¸ Usage
1. Run the GUI
bash
Copy
Edit
python main.py
2. Train the Agent
Go to the Controls tab.

Click Train Agent to begin PPO training.

Model is saved as stall_recovery_agent.zip.

3. Evaluate the Agent
Click Evaluate Agent to run a test simulation.

Watch the Flight Data and Analysis tabs update in real time.

ğŸ“Š Visualizations
Flight Data Tab: Displays a plot of Angle of Attack vs. Altitude over time.

Analysis Tab: Contains scatter, line, and bar plots for:

AoA

Altitude

Speed

Vertical speed

Throttle

Roll

Stall margin

ğŸ“‚ File Structure
python
Copy
Edit
.
â”œâ”€â”€ AircraftSHAgent.py       # Gym environment + PPO training/evaluation
â”œâ”€â”€ main.py                  # PyQt6 GUI application
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ requirements.txt         # Required dependencies
â””â”€â”€ stall_recovery_agent.zip # (generated) trained model file
âš™ï¸ How It Works
The RL agent receives a 7-dimensional observation space (alpha, speed, pitch rate, etc.).

It controls elevator and throttle to adjust flight state.

Rewards are computed based on angle-of-attack and altitude preservation.

Termination occurs on successful recovery or crash.

The GUI tracks the state, logs metrics, and provides intuitive visual feedback.

ğŸ“Œ Future Enhancements
âœ… Integrate real-world flight data logs.

ğŸ”² Add 3D visual model or simulation playback.

ğŸ”² Expand to more aircraft models.

ğŸ”² Incorporate adverse weather conditions and control surface failures.
